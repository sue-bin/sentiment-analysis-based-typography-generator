{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lexicon에 있는 키워드로 typography 이미지 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "EXokJyhSa0Jy"
   },
   "outputs": [],
   "source": [
    "### import packages ###\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import requests\n",
    "import urllib.request\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import unicodedata\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>emotion</th>\n",
       "      <th>association</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aback</td>\n",
       "      <td>anger</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aback</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aback</td>\n",
       "      <td>disgust</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aback</td>\n",
       "      <td>fear</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aback</td>\n",
       "      <td>joy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word       emotion  association\n",
       "0  aback         anger            0\n",
       "1  aback  anticipation            0\n",
       "2  aback       disgust            0\n",
       "3  aback          fear            0\n",
       "4  aback           joy            0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### data load ###\n",
    "path = \"C:/Users/ASUX/Desktop/컨퍼런스/Lexicon_data.txt\"\n",
    "data = pd.read_csv(path, names=[\"word\", \"emotion\", \"association\"], sep='\\t')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### search list ###\n",
    "angry = data[(data.association == 1) & (data.emotion == 'anger')].word.to_list()\n",
    "anticipation = data[(data.association == 1) & (data.emotion == 'anticipation')].word.to_list()\n",
    "disgust = data[(data.association == 1) & (data.emotion == 'disgust')].word.to_list()\n",
    "fear = data[(data.association == 1) & (data.emotion == 'fear')].word.to_list()\n",
    "joy = data[(data.association == 1) & (data.emotion == 'joy')].word.to_list()\n",
    "negative = data[(data.association == 1) & (data.emotion == 'negative')].word.to_list()\n",
    "positive = data[(data.association == 1) & (data.emotion == 'positive')].word.to_list()\n",
    "sadness = data[(data.association == 1) & (data.emotion == 'sadness')].word.to_list()\n",
    "surprise = data[(data.association == 1) & (data.emotion == 'surprise')].word.to_list()\n",
    "trust = data[(data.association == 1) & (data.emotion == 'trust')].word.to_list()\n",
    "\n",
    "emotion = list(data.emotion.unique())\n",
    "text = ['typography', 'typeface', 'font']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "vZ2TWkn9a0F9"
   },
   "outputs": [],
   "source": [
    "### setting ###\n",
    "# 이미지를 저장할 'img' 디렉토리를 미리 생성\n",
    "path = 'C:/Users/ASUX/Desktop/chromedriver_win32/chromedriver'\n",
    "SCROLL_NUM = 5\n",
    "CRAWLING_NUM = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url(driver, emotion, text):\n",
    "    url = \"https://www.google.co.kr/search?q=\" + str(emotion) + \" \" + str(text)\n",
    "    driver.get(url)\n",
    "    driver.find_element_by_class_name('hide-focus-ring').click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    html = driver.page_source\n",
    "    soup = bs(html, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scroll(drive, scroll_num):\n",
    "    \n",
    "    for i in range(scroll_num):\n",
    "        driver.execute_script('window.scrollTo(0,document.body.scrollHeight);')\n",
    "        time.sleep(2)\n",
    "        \n",
    "    driver.execute_script('window.scrollTo(0,0);')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl(driver, crawl_num, emotion, text):\n",
    "    \n",
    "    x = 1\n",
    "    n = 1\n",
    "    driver.find_elements_by_css_selector(\".bRMDJf.islir\")[0].click()\n",
    "    time.sleep(1.5)\n",
    "    \n",
    "    for i in range(crawl_num):\n",
    "        img_url = driver.find_elements_by_class_name('n3VNCb')[0].get_property('src')\n",
    "        image_name = emotion + ' ' + text + '_' + str(n) + '.jpg'\n",
    "                    \n",
    "        try:\n",
    "            with urllib.request.urlopen(img_url) as f:\n",
    "                with open('./img/' + emotion + ' ' + text + '_' + str(n) + '.jpg', 'wb') as h:\n",
    "                    img = f.read()\n",
    "                    h.write(img)\n",
    "\n",
    "            # data_frame 저장용\n",
    "            image_url_list.append(img_url)\n",
    "            image_name_list.append(image_name)\n",
    "\n",
    "            driver.find_elements_by_class_name(\"CIF8af\")[x].click() # 다음 이미지 선택\n",
    "            time.sleep(2)\n",
    "            x = 3\n",
    "            n += 1\n",
    "\n",
    "        except:\n",
    "            driver.find_elements_by_class_name(\"CIF8af\")[x].click() # 다음 이미지 선택\n",
    "            time.sleep(2)\n",
    "            x = 3\n",
    "            n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### crawling ###\n",
    "image_name_list = []\n",
    "image_url_list = []\n",
    "\n",
    "driver = webdriver.Chrome(path)\n",
    "driver.maximize_window()\n",
    "driver.get('https://www.google.co.kr/')\n",
    "time.sleep(1)\n",
    "\n",
    "for emo in emotion: # search list에서 인덱싱\n",
    "    for t in text:\n",
    "        get_url(driver, emo, t)\n",
    "        time.sleep(2)\n",
    "        scroll(driver, SCROLL_NUM)\n",
    "        time.sleep(2)\n",
    "        crawl(driver, CRAWLING_NUM, emo, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "eZKK1Q9AbC7d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>image_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anger typography_1.jpg</td>\n",
       "      <td>https://i.pinimg.com/originals/17/61/eb/1761eb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anger typography_2.jpg</td>\n",
       "      <td>https://i.pinimg.com/originals/17/61/eb/1761eb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anger typography_3.jpg</td>\n",
       "      <td>https://fontesk.com/wp-content/uploads/2020/10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anger typography_4.jpg</td>\n",
       "      <td>https://previews.123rf.com/images/ponytail1414...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>anger typography_5.jpg</td>\n",
       "      <td>https://pro2-bar-s3-cdn-cf4.myportfolio.com/5a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               image_name                                          image_url\n",
       "0  anger typography_1.jpg  https://i.pinimg.com/originals/17/61/eb/1761eb...\n",
       "1  anger typography_2.jpg  https://i.pinimg.com/originals/17/61/eb/1761eb...\n",
       "2  anger typography_3.jpg  https://fontesk.com/wp-content/uploads/2020/10...\n",
       "3  anger typography_4.jpg  https://previews.123rf.com/images/ponytail1414...\n",
       "4  anger typography_5.jpg  https://pro2-bar-s3-cdn-cf4.myportfolio.com/5a..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### save ###\n",
    "data = {'image_name':image_name_list,\n",
    "        'image_url':image_url_list}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.head()\n",
    "#df.to_csv('data.csv', index=True, encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO3KcT0y4IWAnW5SglJg4D7",
   "collapsed_sections": [],
   "name": "Lexicon_Image_Crawler.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
